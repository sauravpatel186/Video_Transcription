{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"c56161a939430l3396553t1w744137092661-labbucket-rn642jaq01e9\"\n",
    "job_data_access_role = 'arn:aws:iam::744137092661:role/service-role/c56161a939430l3396553t1w7-ComprehendDataAccessRole-1P24MSS91ADHP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Viewing the video files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 20:17:33  410925369 Mod01_Course Overview.mp4\r\n",
      "2021-04-26 20:10:02   39576695 Mod02_Intro.mp4\r\n",
      "2021-04-26 20:31:23  302994828 Mod02_Sect01.mp4\r\n",
      "2021-04-26 20:17:33  416563881 Mod02_Sect02.mp4\r\n",
      "2021-04-26 20:17:33  318685583 Mod02_Sect03.mp4\r\n",
      "2021-04-26 20:17:33  255877251 Mod02_Sect04.mp4\r\n",
      "2021-04-26 20:23:51   99988046 Mod02_Sect05.mp4\r\n",
      "2021-04-26 20:24:54   50700224 Mod02_WrapUp.mp4\r\n",
      "2021-04-26 20:26:27   60627667 Mod03_Intro.mp4\r\n",
      "2021-04-26 20:26:28  272229844 Mod03_Sect01.mp4\r\n",
      "2021-04-26 20:27:06  309127124 Mod03_Sect02_part1.mp4\r\n",
      "2021-04-26 20:27:06  195635527 Mod03_Sect02_part2.mp4\r\n",
      "2021-04-26 20:28:03  123924818 Mod03_Sect02_part3.mp4\r\n",
      "2021-04-26 20:31:28  171681915 Mod03_Sect03_part1.mp4\r\n",
      "2021-04-26 20:32:07  285200083 Mod03_Sect03_part2.mp4\r\n",
      "2021-04-26 20:33:17  105470345 Mod03_Sect03_part3.mp4\r\n",
      "2021-04-26 20:35:10  157185651 Mod03_Sect04_part1.mp4\r\n",
      "2021-04-26 20:36:27  187435635 Mod03_Sect04_part2.mp4\r\n",
      "2021-04-26 20:36:40  280720369 Mod03_Sect04_part3.mp4\r\n",
      "2021-04-26 20:40:01  443479313 Mod03_Sect05.mp4\r\n",
      "2021-04-26 20:40:08  234182186 Mod03_Sect06.mp4\r\n",
      "2021-04-26 20:40:33  207718047 Mod03_Sect07_part1.mp4\r\n",
      "2021-04-26 20:42:07  125592110 Mod03_Sect07_part2.mp4\r\n",
      "2021-04-26 20:45:10  508500301 Mod03_Sect07_part3.mp4\r\n",
      "2021-04-26 20:46:16  320126756 Mod03_Sect08.mp4\r\n",
      "2021-04-26 20:46:43   41839508 Mod03_WrapUp.mp4\r\n",
      "2021-04-26 20:46:55   34148489 Mod04_Intro.mp4\r\n",
      "2021-04-26 20:48:24   84959465 Mod04_Sect01.mp4\r\n",
      "2021-04-26 20:48:25  345182970 Mod04_Sect02_part1.mp4\r\n",
      "2021-04-26 20:51:34  218661651 Mod04_Sect02_part2.mp4\r\n",
      "2021-04-26 20:53:32  430140637 Mod04_Sect02_part3.mp4\r\n",
      "2021-04-26 20:56:03   22036605 Mod04_WrapUp.mp4\r\n",
      "2021-04-26 20:57:18   49187118 Mod05_Intro.mp4\r\n",
      "2021-04-26 20:58:19  245798071 Mod05_Sect01_ver2.mp4\r\n",
      "2021-04-26 20:58:50  233314835 Mod05_Sect02_part1_ver2.mp4\r\n",
      "2021-04-26 20:59:14  348545306 Mod05_Sect02_part2.mp4\r\n",
      "2021-04-26 20:59:17  239142711 Mod05_Sect03_part1.mp4\r\n",
      "2021-04-26 21:06:04  267533559 Mod05_Sect03_part2.mp4\r\n",
      "2021-04-26 21:06:06  212502220 Mod05_Sect03_part3.mp4\r\n",
      "2021-04-26 21:06:48  206317022 Mod05_Sect03_part4_ver2.mp4\r\n",
      "2021-04-26 21:06:48   60361230 Mod05_WrapUp_ver2.mp4\r\n",
      "2021-04-26 21:09:14   35397860 Mod06_Intro.mp4\r\n",
      "2021-04-26 21:09:24  845633599 Mod06_Sect01.mp4\r\n",
      "2021-04-26 21:10:47  326126684 Mod06_Sect02.mp4\r\n",
      "2021-04-26 21:12:26   19790740 Mod06_WrapUp.mp4\r\n",
      "2021-04-26 21:12:56  131249036 Mod07_Sect01.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.29.2)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from moviepy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from moviepy) (2.34.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (69.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy transformers accelerate torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transcribing the videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline   \n",
    "device_map = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device_map = \"cuda:0\"\n",
    "else:\n",
    "    device_map = \"cpu\"\n",
    "torch_dtype = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    torch_dtype = torch.float32\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model_version = \"openai/whisper-large-v3\"\n",
    "whisper = AutoModelForSpeechSeq2Seq.from_pretrained( model_version, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True)\n",
    "whisper.to(device_map)\n",
    "processor = AutoProcessor.from_pretrained(model_version)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device_map,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = \"aws-tc-largeobjects\"\n",
    "key  = \"CUR-TF-200-ACMNLP-1/video/\"\n",
    "response = s3.list_objects_v2(Bucket=\"aws-tc-largeobjects\", Prefix=\"CUR-TF-200-ACMNLP-1/video/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5033:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2501:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5033:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2501:(snd_pcm_open_noupdate) Unknown PCM default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod01_Course Overview.mp4']\n",
      "['Mod01_Course Overview', 'mp4']\n",
      "MoviePy - Writing audio in Mod01_Course Overview.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Intro.mp4']\n",
      "['Mod02_Intro', 'mp4']\n",
      "MoviePy - Writing audio in Mod02_Intro.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect01.mp4']\n",
      "['Mod02_Sect01', 'mp4']\n",
      "MoviePy - Writing audio in Mod02_Sect01.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect02.mp4']\n",
      "['Mod02_Sect02', 'mp4']\n",
      "MoviePy - Writing audio in Mod02_Sect02.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect03.mp4']\n",
      "['Mod02_Sect03', 'mp4']\n",
      "MoviePy - Writing audio in Mod02_Sect03.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect04.mp4']\n",
      "['Mod02_Sect04', 'mp4']\n",
      "MoviePy - Writing audio in Mod02_Sect04.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect05.mp4']\n",
      "['Mod02_Sect05', 'mp4']\n",
      "MoviePy - Writing audio in Mod02_Sect05.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_WrapUp.mp4']\n",
      "['Mod02_WrapUp', 'mp4']\n",
      "MoviePy - Writing audio in Mod02_WrapUp.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Intro.mp4']\n",
      "['Mod03_Intro', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Intro.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect01.mp4']\n",
      "['Mod03_Sect01', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect01.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect02_part1.mp4']\n",
      "['Mod03_Sect02_part1', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect02_part1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect02_part2.mp4']\n",
      "['Mod03_Sect02_part2', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect02_part2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect02_part3.mp4']\n",
      "['Mod03_Sect02_part3', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect02_part3.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect03_part1.mp4']\n",
      "['Mod03_Sect03_part1', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect03_part1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect03_part2.mp4']\n",
      "['Mod03_Sect03_part2', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect03_part2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect03_part3.mp4']\n",
      "['Mod03_Sect03_part3', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect03_part3.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect04_part1.mp4']\n",
      "['Mod03_Sect04_part1', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect04_part1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect04_part2.mp4']\n",
      "['Mod03_Sect04_part2', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect04_part2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect04_part3.mp4']\n",
      "['Mod03_Sect04_part3', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect04_part3.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect05.mp4']\n",
      "['Mod03_Sect05', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect05.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect06.mp4']\n",
      "['Mod03_Sect06', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect06.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect07_part1.mp4']\n",
      "['Mod03_Sect07_part1', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect07_part1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect07_part2.mp4']\n",
      "['Mod03_Sect07_part2', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect07_part2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect07_part3.mp4']\n",
      "['Mod03_Sect07_part3', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect07_part3.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect08.mp4']\n",
      "['Mod03_Sect08', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_Sect08.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_WrapUp.mp4']\n",
      "['Mod03_WrapUp', 'mp4']\n",
      "MoviePy - Writing audio in Mod03_WrapUp.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Intro.mp4']\n",
      "['Mod04_Intro', 'mp4']\n",
      "MoviePy - Writing audio in Mod04_Intro.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect01.mp4']\n",
      "['Mod04_Sect01', 'mp4']\n",
      "MoviePy - Writing audio in Mod04_Sect01.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect02_part1.mp4']\n",
      "['Mod04_Sect02_part1', 'mp4']\n",
      "MoviePy - Writing audio in Mod04_Sect02_part1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect02_part2.mp4']\n",
      "['Mod04_Sect02_part2', 'mp4']\n",
      "MoviePy - Writing audio in Mod04_Sect02_part2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect02_part3.mp4']\n",
      "['Mod04_Sect02_part3', 'mp4']\n",
      "MoviePy - Writing audio in Mod04_Sect02_part3.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_WrapUp.mp4']\n",
      "['Mod04_WrapUp', 'mp4']\n",
      "MoviePy - Writing audio in Mod04_WrapUp.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Intro.mp4']\n",
      "['Mod05_Intro', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Intro.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect01_ver2.mp4']\n",
      "['Mod05_Sect01_ver2', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Sect01_ver2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect02_part1_ver2.mp4']\n",
      "['Mod05_Sect02_part1_ver2', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Sect02_part1_ver2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect02_part2.mp4']\n",
      "['Mod05_Sect02_part2', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Sect02_part2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part1.mp4']\n",
      "['Mod05_Sect03_part1', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Sect03_part1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part2.mp4']\n",
      "['Mod05_Sect03_part2', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Sect03_part2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part3.mp4']\n",
      "['Mod05_Sect03_part3', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Sect03_part3.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part4_ver2.mp4']\n",
      "['Mod05_Sect03_part4_ver2', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_Sect03_part4_ver2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_WrapUp_ver2.mp4']\n",
      "['Mod05_WrapUp_ver2', 'mp4']\n",
      "MoviePy - Writing audio in Mod05_WrapUp_ver2.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_Intro.mp4']\n",
      "['Mod06_Intro', 'mp4']\n",
      "MoviePy - Writing audio in Mod06_Intro.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_Sect01.mp4']\n",
      "['Mod06_Sect01', 'mp4']\n",
      "MoviePy - Writing audio in Mod06_Sect01.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_Sect02.mp4']\n",
      "['Mod06_Sect02', 'mp4']\n",
      "MoviePy - Writing audio in Mod06_Sect02.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_WrapUp.mp4']\n",
      "['Mod06_WrapUp', 'mp4']\n",
      "MoviePy - Writing audio in Mod06_WrapUp.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod07_Sect01.mp4']\n",
      "['Mod07_Sect01', 'mp4']\n",
      "MoviePy - Writing audio in Mod07_Sect01.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "from moviepy.editor import *\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "folder_path = 'text_files'\n",
    "if os.path.exists(folder_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = \"aws-tc-largeobjects\"\n",
    "key  = \"CUR-TF-200-ACMNLP-1/video/\"\n",
    "response = s3.list_objects_v2(Bucket=\"aws-tc-largeobjects\", Prefix=\"CUR-TF-200-ACMNLP-1/video/\")\n",
    "def convert_to_audio():\n",
    "    for obj in response[\"Contents\"]:\n",
    "        file_name = obj[\"Key\"].split(\"/\")\n",
    "        print(file_name)\n",
    "        s3.download_file(bucket_name,obj[\"Key\"],file_name[2])\n",
    "        video_file = VideoFileClip(file_name[2])\n",
    "        audio_file = video_file.audio\n",
    "        file = file_name[2].split(\".\")\n",
    "        print(file)\n",
    "        audio_file.write_audiofile(f\"{file[0]}.mp3\")\n",
    "        os.remove(file_name[2])\n",
    "        video_file.close()\n",
    "        audio_file.close()\n",
    "convert_to_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_5118/4200420437.py\", line 10, in <module>\n",
      "    convert_to_text()\n",
      "  File \"/tmp/ipykernel_5118/4200420437.py\", line 6, in convert_to_text\n",
      "    result = pipe(f\"{audio_file}.mp3\")\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 285, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_text():\n",
    "    for obj in response[\"Contents\"]:\n",
    "        file_name = obj[\"Key\"].split(\"/\")\n",
    "        file = file_name[2].split(\".\")\n",
    "        audio_file = file[0]\n",
    "        result = pipe(f\"{audio_file}.mp3\")\n",
    "        with open(f\"{folder_path}/{audio_file}.txt\", 'w',encoding =\"UTF-8\") as file:\n",
    "            file.write(result[\"text\"])\n",
    "    \n",
    "convert_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalizing the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod01_Course Overview.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Intro.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect01.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect02.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect03.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect04.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_Sect05.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod02_WrapUp.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Intro.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect01.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect02_part1.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect02_part2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect02_part3.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect03_part1.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect03_part2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect03_part3.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect04_part1.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect04_part2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect04_part3.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect05.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect06.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect07_part1.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect07_part2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect07_part3.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_Sect08.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod03_WrapUp.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Intro.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect01.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect02_part1.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect02_part2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_Sect02_part3.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod04_WrapUp.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Intro.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect01_ver2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect02_part1_ver2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect02_part2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part1.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part3.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_Sect03_part4_ver2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod05_WrapUp_ver2.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_Intro.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_Sect01.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_Sect02.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod06_WrapUp.mp4']\n",
      "['CUR-TF-200-ACMNLP-1', 'video', 'Mod07_Sect01.mp4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "def normalize(data):\n",
    "    filtered_sentence = []\n",
    "    word = data.lower()\n",
    "    word = re.sub('\\s+', ' ',word)\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    words = word_tokenize(word)\n",
    "    d = set(stopwords.words(\"english\"))\n",
    "    for text in words:\n",
    "        if text not in d:\n",
    "            filtered_sentence.append(text)\n",
    "    sentence = \" \".join(filtered_sentence)\n",
    "    return sentence\n",
    "def read_text():\n",
    "    t = \"\"\n",
    "    folder_path_text = \"normalized_text\"\n",
    "    for obj in response[\"Contents\"]:\n",
    "        file_name = obj[\"Key\"].split(\"/\")\n",
    "        file = file_name[2].split(\".\")\n",
    "        text_file = f\"text_files/{file[0]}.txt\"\n",
    "        print(file_name)\n",
    "        normalize_file = f\"normalized_text/{file[0]}.txt\"\n",
    "        with open(text_file,\"r\",encoding=\"UTF-8\") as file:\n",
    "            data  = file.read()\n",
    "            text = normalize(data)\n",
    "            \n",
    "            if os.path.exists(f\"{folder_path_text}\"):\n",
    "                pass\n",
    "            else:\n",
    "                os.makedirs(f\"{folder_path_text}\")\n",
    "            with open(f\"{normalize_file}\",\"w\") as file_2:\n",
    "                file_2.write(text)\n",
    "            t+=text\n",
    "    return t\n",
    "text = read_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extracting key phrases and topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keybert in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.8.4)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from keybert) (2.6.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from keybert) (1.4.1.post1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from keybert) (1.26.4)\n",
      "Requirement already satisfied: rich>=10.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from keybert) (13.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=10.4.0->keybert) (2.17.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (3.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.39.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (0.22.2)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (4.9.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_bert_model = KeyBERT(model='all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for obj in response[\"Contents\"]:\n",
    "    file_name = obj[\"Key\"].split(\"/\")\n",
    "    file = file_name[2].split(\".\")\n",
    "    text_file = f\"normalized_text/{file[0]}.txt\"\n",
    "    folder_name  = \"transribed_files\"\n",
    "    with open(f\"{text_file}\",\"r\") as file_2:\n",
    "        data = file_2.read()\n",
    "        output = key_bert_model.extract_keywords(data, \n",
    "                                         stop_words='english',\n",
    "                                         keyphrase_ngram_range=(2, 3), \n",
    "                                         top_n=10,\n",
    "                                         highlight=False,\n",
    "                                         use_maxsum=True,\n",
    "                                         nr_candidates =20,\n",
    "                                         diversity=0.7)\n",
    "        key_phrase= list(dict(output).keys())\n",
    "        if os.path.exists(folder_name):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(folder_name)\n",
    "        with open(f\"{folder_name}/{file[0]}.txt\",\"w\") as file_3:\n",
    "            for data in key_phrase:\n",
    "                file_3.write(data+\"\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "for obj in response[\"Contents\"]:\n",
    "    file_name = obj[\"Key\"].split(\"/\")\n",
    "    file = file_name[2].split(\".\")\n",
    "    text_file = f\"normalized_text/{file[0]}.txt\"\n",
    "    folder_name  = \"transribed_files\"\n",
    "    with open(f\"{text_file}\",\"r\") as file_2:\n",
    "        text = file_2.read()\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        n=2\n",
    "        top=5\n",
    "        data_sequence = ngrams(tokens, n)\n",
    "        data_frequency= Counter(data_sequence)\n",
    "        data_gram = data_frequency.most_common(top)\n",
    "        with open(f\"{folder_name}/{file[0]}.txt\",\"a\") as file_3:\n",
    "            for i in data_gram:\n",
    "                d= i[0][0]+\" \"+i[0][1]\n",
    "                \n",
    "                file_3.write(d+\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating the dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9ca1518d4d4cc1bdbc5976ad5faf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Enter text to search')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea61698fbf54e069d34e8db828e4f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Search', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output,Video,HTML\n",
    "import os\n",
    "bucket_name = \"aws-tc-largeobjects\"\n",
    "key  = \"CUR-TF-200-ACMNLP-1/video/\"\n",
    "text = \"\"\n",
    "import time \n",
    "def find_file(keyword):\n",
    "    files_name = []\n",
    "    for transcribed_file in os.listdir(\"transribed_files\"):\n",
    "        if transcribed_file == \"..ipynb_checkpoints\":\n",
    "            pass\n",
    "        with open(os.path.join('transribed_files',transcribed_file), 'r') as file:\n",
    "                if keyword in file.read():\n",
    "                    files_name.append(transcribed_file)\n",
    "    return files_name               \n",
    "def fetch_video(file):\n",
    "    url = f\"https://{bucket_name}.s3.amazonaws.com/{key}{file}.mp4\"\n",
    "    return url\n",
    "def load_video(file):\n",
    "    url = fetch_video(file)\n",
    "    time.sleep(1)\n",
    "    display(Video(url,width=800))\n",
    "    \n",
    "def listbox_options_handler(option):\n",
    "    options = None\n",
    "    options = option['new']\n",
    "    load_video(options)\n",
    "def displaying_listbox(file):\n",
    "    display(text_bar, search_button)\n",
    "    list_box_widget = widgets.Select(\n",
    "    options=file,\n",
    "    description='Please Select the video')\n",
    "    list_box_widget.observe(listbox_options_handler, names='value')\n",
    "    display(list_box_widget)\n",
    "    display(HTML(\"<p> Please double click on the options to view the video\"))\n",
    "def on_button_click(b):\n",
    "    clear_output()\n",
    "    text_search = text_bar.value\n",
    "    text = text_bar.value\n",
    "    file_list = find_file(text_search.lower())\n",
    "    file_data = []\n",
    "    \n",
    "    if file_list:\n",
    "        for file_name in file_list:\n",
    "            temp = file_name.split(\".\")\n",
    "            file_data.append(temp[0])\n",
    "        displaying_listbox(file_data)\n",
    "    else:\n",
    "        print(\"Sorry no file found with string matching {}.\".format(text_search))\n",
    "    return file_list\n",
    "\n",
    "text_bar = widgets.Text(placeholder='Enter text to search')\n",
    "search_button = widgets.Button(description='Search',disabled=False)\n",
    "search_button.on_click(on_button_click)\n",
    "display(text_bar, search_button)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
